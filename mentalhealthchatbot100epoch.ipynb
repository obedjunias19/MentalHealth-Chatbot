{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-03T09:45:24.896691Z","iopub.execute_input":"2023-11-03T09:45:24.896941Z","iopub.status.idle":"2023-11-03T09:45:25.239352Z","shell.execute_reply.started":"2023-11-03T09:45:24.896917Z","shell.execute_reply":"2023-11-03T09:45:25.238519Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!pip install trl transformers accelerate git+https://github.com/huggingface/peft.git -Uqqq\n!pip install datasets bitsandbytes einops wandb -Uqqq","metadata":{"execution":{"iopub.status.busy":"2023-11-03T09:45:25.240863Z","iopub.execute_input":"2023-11-03T09:45:25.241207Z","iopub.status.idle":"2023-11-03T09:46:31.924666Z","shell.execute_reply.started":"2023-11-03T09:45:25.241183Z","shell.execute_reply":"2023-11-03T09:46:31.923599Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, TrainingArguments\nfrom trl import SFTTrainer","metadata":{"execution":{"iopub.status.busy":"2023-11-03T09:46:31.926093Z","iopub.execute_input":"2023-11-03T09:46:31.926419Z","iopub.status.idle":"2023-11-03T09:46:55.093789Z","shell.execute_reply.started":"2023-11-03T09:46:31.926390Z","shell.execute_reply":"2023-11-03T09:46:55.092754Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch","metadata":{"execution":{"iopub.status.busy":"2023-11-03T09:46:55.096412Z","iopub.execute_input":"2023-11-03T09:46:55.096863Z","iopub.status.idle":"2023-11-03T09:46:55.102286Z","shell.execute_reply.started":"2023-11-03T09:46:55.096820Z","shell.execute_reply":"2023-11-03T09:46:55.101083Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import os\nimport bitsandbytes as bnb\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport transformers\nfrom datasets import load_dataset\nfrom peft import (\n    LoraConfig,\n    PeftConfig,\n    get_peft_model,\n    prepare_model_for_kbit_training,\n)\nfrom transformers import (\n    AutoConfig,\n    AutoModelForCausalLM,\n    AutoTokenizer,\n    BitsAndBytesConfig,\n)","metadata":{"execution":{"iopub.status.busy":"2023-11-03T09:52:52.716852Z","iopub.execute_input":"2023-11-03T09:52:52.717689Z","iopub.status.idle":"2023-11-03T09:52:52.723348Z","shell.execute_reply.started":"2023-11-03T09:52:52.717653Z","shell.execute_reply":"2023-11-03T09:52:52.722093Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"model_name = \"ybelkada/falcon-7b-sharded-bf16\" # falcon-7b model\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    load_4bit_use_double_quant=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch.bfloat16,\n)\n\nmodel =AutoModelForCausalLM.from_pretrained(\n    model_name,\n    device_map=\"auto\",\n    trust_remote_code=True,\n    quantization_config=bnb_config,\n)","metadata":{"execution":{"iopub.status.busy":"2023-11-03T09:48:04.033226Z","iopub.execute_input":"2023-11-03T09:48:04.033666Z","iopub.status.idle":"2023-11-03T09:50:40.373161Z","shell.execute_reply.started":"2023-11-03T09:48:04.033619Z","shell.execute_reply":"2023-11-03T09:50:40.372096Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/581 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e3356fdb891b485d9d685c5acfea89e5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)model.bin.index.json:   0%|          | 0.00/16.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"17d99cdbd094459d8dba6812011e2bf1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/8 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7b57808e0e6e4a9fb5a964f60d9bdce5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)l-00001-of-00008.bin:   0%|          | 0.00/1.92G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c726c381e91349afa887cb99fc3f95dd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)l-00002-of-00008.bin:   0%|          | 0.00/1.99G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2a318dbb2e9a4e888acc6519671cd7df"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)l-00003-of-00008.bin:   0%|          | 0.00/1.91G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c4ab87fe117434aa328849a7df16c2f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)l-00004-of-00008.bin:   0%|          | 0.00/1.91G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c1ad120f6b024fe48071044c314911ce"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)l-00005-of-00008.bin:   0%|          | 0.00/1.99G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"18f7454032164a5fb02cceaf7dbb4e87"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)l-00006-of-00008.bin:   0%|          | 0.00/1.91G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ffb5ddf8790b47bbb5779fd18385ba30"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)l-00007-of-00008.bin:   0%|          | 0.00/1.91G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2abfae225e5a4b568859b68d1653e70e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)l-00008-of-00008.bin:   0%|          | 0.00/921M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"77ccb842518d41778ef05965b131b53b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0ea04afe97a844bd8068b0dfb3492027"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)neration_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"17102e36f6664717a199d604f7fa0405"}},"metadata":{}}]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\ntokenizer.pad_token = tokenizer.eos_token # Setting pad_token same as eos_token","metadata":{"execution":{"iopub.status.busy":"2023-11-03T09:52:20.527968Z","iopub.execute_input":"2023-11-03T09:52:20.528366Z","iopub.status.idle":"2023-11-03T09:52:21.284241Z","shell.execute_reply.started":"2023-11-03T09:52:20.528330Z","shell.execute_reply":"2023-11-03T09:52:21.282989Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/180 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3eb3e4f31696418893fc0d380a709d03"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)/main/tokenizer.json:   0%|          | 0.00/2.73M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"513eefe212a94997a231392f4271daff"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)cial_tokens_map.json:   0%|          | 0.00/281 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fbf944a22937428e9a0d62c634f50904"}},"metadata":{}}]},{"cell_type":"code","source":"# model.gradient_checkpointing_enable()","metadata":{"execution":{"iopub.status.busy":"2023-11-03T10:37:43.285838Z","iopub.execute_input":"2023-11-03T10:37:43.286277Z","iopub.status.idle":"2023-11-03T10:37:43.291947Z","shell.execute_reply.started":"2023-11-03T10:37:43.286227Z","shell.execute_reply":"2023-11-03T10:37:43.291022Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"model = prepare_model_for_kbit_training(model)","metadata":{"execution":{"iopub.status.busy":"2023-11-03T09:52:58.925744Z","iopub.execute_input":"2023-11-03T09:52:58.926653Z","iopub.status.idle":"2023-11-03T09:52:58.942131Z","shell.execute_reply.started":"2023-11-03T09:52:58.926614Z","shell.execute_reply":"2023-11-03T09:52:58.941152Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"lora_alpha = 32 # scaling factor for the weight matrices\nlora_dropout = 0.05 # dropout probability of the LoRA layers\nlora_rank = 32 # dimension of the low-rank matrices\n\npeft_config = LoraConfig(\n    lora_alpha=lora_alpha,\n    lora_dropout=lora_dropout,\n    r=lora_rank,\n    bias=\"none\",  # setting to 'none' for only training weight params instead of biases\n    task_type=\"CAUSAL_LM\",\n    target_modules=[         # Setting names of modules in falcon-7b model that we want to apply LoRA to\n        \"query_key_value\",\n        \"dense\",\n        \"dense_h_to_4h\",\n        \"dense_4h_to_h\",\n    ]\n)\n\npeft_model = get_peft_model(model, peft_config)","metadata":{"execution":{"iopub.status.busy":"2023-11-03T09:53:15.753671Z","iopub.execute_input":"2023-11-03T09:53:15.754021Z","iopub.status.idle":"2023-11-03T09:53:16.693446Z","shell.execute_reply.started":"2023-11-03T09:53:15.753993Z","shell.execute_reply":"2023-11-03T09:53:16.692439Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"from datasets import load_dataset\n\ndata = load_dataset(\"heliosbrahma/mental_health_conversational_dataset\")","metadata":{"execution":{"iopub.status.busy":"2023-11-03T09:54:59.487120Z","iopub.execute_input":"2023-11-03T09:54:59.488023Z","iopub.status.idle":"2023-11-03T09:55:01.578415Z","shell.execute_reply.started":"2023-11-03T09:54:59.487983Z","shell.execute_reply":"2023-11-03T09:55:01.577632Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/2.58k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"640dd17244974a5ea3409c799e3a99e0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b07d26430b9d4a039c4ea16cb484588b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/60.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"88eb5cecc8ba4a17bc6bc925f0b280ae"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4f0dc6a4d3d44126960ab338aa906b62"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/154 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e6a5174e4da74632b19c9171ffbf05d6"}},"metadata":{}}]},{"cell_type":"code","source":"from huggingface_hub import notebook_login\n\nnotebook_login()","metadata":{"execution":{"iopub.status.busy":"2023-11-03T09:59:33.198322Z","iopub.execute_input":"2023-11-03T09:59:33.199287Z","iopub.status.idle":"2023-11-03T09:59:33.221589Z","shell.execute_reply.started":"2023-11-03T09:59:33.199229Z","shell.execute_reply":"2023-11-03T09:59:33.220660Z"},"trusted":true},"execution_count":21,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9b61ad77c3a04e9da3e4fc8832a6bc42"}},"metadata":{}}]},{"cell_type":"code","source":"output_dir = \"./falcon-7b-sharded-bf16-finetuned-mental-health-conversational\"\nper_device_train_batch_size = 4 # reduce batch size by 2x if out-of-memory error\ngradient_accumulation_steps = 4  # increase gradient accumulation steps by 2x if batch size is reduced\noptim = \"paged_adamw_8bit\" # activates the paging for better memory management\nsave_strategy=\"steps\" # checkpoint save strategy to adopt during training\nsave_steps = 10 # number of updates steps before two checkpoint saves\nlogging_steps = 10  # number of update steps between two logs if logging_strategy=\"steps\"\nlearning_rate = 2e-4  # learning rate for AdamW optimizer\nmax_grad_norm = 0.3 # maximum gradient norm (for gradient clipping)\nmax_steps = 100        # training will happen for 320 steps\nwarmup_ratio = 0.03 # number of steps used for a linear warmup from 0 to learning_rate\nlr_scheduler_type = \"cosine\"  # learning rate scheduler\n\ntraining_arguments = TrainingArguments(\n    output_dir=output_dir,\n    per_device_train_batch_size=per_device_train_batch_size,\n    gradient_accumulation_steps=gradient_accumulation_steps,\n    optim=optim,\n    save_steps=save_steps,\n    logging_steps=logging_steps,\n    learning_rate=learning_rate,\n    bf16=False,\n    fp16=True,\n    max_grad_norm=max_grad_norm,\n    max_steps=max_steps,\n    warmup_ratio=warmup_ratio,\n    group_by_length=True,\n    lr_scheduler_type=lr_scheduler_type,\n    push_to_hub=True,\n)\n\ntrainer = SFTTrainer(\n    model=peft_model,\n    train_dataset=data['train'],\n    peft_config=peft_config,\n    dataset_text_field=\"text\",\n    max_seq_length=1024,\n    tokenizer=tokenizer,\n    args=training_arguments,\n)","metadata":{"execution":{"iopub.status.busy":"2023-11-03T09:59:39.791182Z","iopub.execute_input":"2023-11-03T09:59:39.791937Z","iopub.status.idle":"2023-11-03T09:59:40.095830Z","shell.execute_reply.started":"2023-11-03T09:59:39.791901Z","shell.execute_reply":"2023-11-03T09:59:40.094827Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"peft_model.config.use_cache = False\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2023-11-03T09:59:53.516275Z","iopub.execute_input":"2023-11-03T09:59:53.516697Z","iopub.status.idle":"2023-11-03T10:23:00.530108Z","shell.execute_reply.started":"2023-11-03T09:59:53.516655Z","shell.execute_reply":"2023-11-03T10:23:00.528976Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.15.12"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20231103_100011-d70tb1z3</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/oj-team/huggingface/runs/d70tb1z3' target=\"_blank\">earthy-haze-4</a></strong> to <a href='https://wandb.ai/oj-team/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/oj-team/huggingface' target=\"_blank\">https://wandb.ai/oj-team/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/oj-team/huggingface/runs/d70tb1z3' target=\"_blank\">https://wandb.ai/oj-team/huggingface/runs/d70tb1z3</a>"},"metadata":{}},{"name":"stderr","text":"You're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\nThe current implementation of Falcon calls `torch.scaled_dot_product_attention` directly, this will be deprecated in the future in favor of the `BetterTransformer` API. Please install the latest optimum library with `pip install -U optimum` and call `model.to_bettertransformer()` to benefit from `torch.scaled_dot_product_attention` and future performance optimizations.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [100/100 21:45, Epoch 10/12]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>10</td>\n      <td>1.948000</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>1.640100</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>1.475800</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>1.257700</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>1.012700</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>0.731400</td>\n    </tr>\n    <tr>\n      <td>70</td>\n      <td>0.555800</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>0.433900</td>\n    </tr>\n    <tr>\n      <td>90</td>\n      <td>0.349000</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.340400</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=100, training_loss=0.9744822978973389, metrics={'train_runtime': 1375.3707, 'train_samples_per_second': 1.163, 'train_steps_per_second': 0.073, 'total_flos': 9966063658535424.0, 'train_loss': 0.9744822978973389, 'epoch': 10.26})"},"metadata":{}}]},{"cell_type":"code","source":"trainer.save_model('.')","metadata":{"execution":{"iopub.status.busy":"2023-11-03T10:24:45.550998Z","iopub.execute_input":"2023-11-03T10:24:45.552011Z","iopub.status.idle":"2023-11-03T10:24:48.571847Z","shell.execute_reply.started":"2023-11-03T10:24:45.551961Z","shell.execute_reply":"2023-11-03T10:24:48.570569Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"def generate_answer(query):\n  system_prompt = \"\"\"Answer the following question truthfully.\n  If you don't know the answer, respond 'Sorry, I don't know the answer to this question.'.\n  If the question is too complex, respond 'Kindly, consult a psychiatrist for further queries.'.\"\"\"\n\n  user_prompt = f\"\"\"<HUMAN>: {query}\n  <ASSISTANT>: \"\"\"\n\n  final_prompt = system_prompt + \"\\n\" + user_prompt\n\n  device = \"cuda:0\"\n  dashline = \"-\".join(\"\" for i in range(50))\n\n  encoding = tokenizer(final_prompt, return_tensors=\"pt\").to(device)\n  outputs = model.generate(input_ids=encoding.input_ids, generation_config=GenerationConfig(max_new_tokens=256, pad_token_id = tokenizer.eos_token_id, \\\n                                                                                                                     eos_token_id = tokenizer.eos_token_id, attention_mask = encoding.attention_mask, \\\n                                                                                                                     temperature=0.4, top_p=0.6, repetition_penalty=1.3, num_return_sequences=1,))\n  text_output = tokenizer.decode(outputs[0], skip_special_tokens=True)\n\n  print(dashline)\n  print(f'ORIGINAL MODEL RESPONSE:\\n{text_output}')\n  print(dashline)\n\n  peft_encoding = peft_tokenizer(final_prompt, return_tensors=\"pt\").to(device)\n  peft_outputs = peft_model.generate(input_ids=peft_encoding.input_ids, generation_config=GenerationConfig(max_new_tokens=256, pad_token_id = peft_tokenizer.eos_token_id, \\\n                                                                                                                     eos_token_id = peft_tokenizer.eos_token_id, attention_mask = peft_encoding.attention_mask, \\\n                                                                                                                     temperature=0.4, top_p=0.6, repetition_penalty=1.3, num_return_sequences=1,))\n  peft_text_output = peft_tokenizer.decode(peft_outputs[0], skip_special_tokens=True)\n\n  print(f'PEFT MODEL RESPONSE:\\n{peft_text_output}')\n  print(dashline)","metadata":{"execution":{"iopub.status.busy":"2023-11-03T10:23:07.940037Z","iopub.execute_input":"2023-11-03T10:23:07.940845Z","iopub.status.idle":"2023-11-03T10:23:07.952295Z","shell.execute_reply.started":"2023-11-03T10:23:07.940807Z","shell.execute_reply":"2023-11-03T10:23:07.951163Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"trainer.model.save_pretrained('.')\ntrainer.tokenizer.save_pretrained('.')","metadata":{"execution":{"iopub.status.busy":"2023-11-03T10:38:55.741963Z","iopub.execute_input":"2023-11-03T10:38:55.742804Z","iopub.status.idle":"2023-11-03T10:38:56.320839Z","shell.execute_reply.started":"2023-11-03T10:38:55.742758Z","shell.execute_reply":"2023-11-03T10:38:56.319320Z"},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"('./tokenizer_config.json', './special_tokens_map.json', './tokenizer.json')"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import GenerationConfig","metadata":{"execution":{"iopub.status.busy":"2023-11-03T10:25:56.229051Z","iopub.execute_input":"2023-11-03T10:25:56.230004Z","iopub.status.idle":"2023-11-03T10:25:56.237259Z","shell.execute_reply.started":"2023-11-03T10:25:56.229959Z","shell.execute_reply":"2023-11-03T10:25:56.236048Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"\n\nquery = \"How can I prevent anxiety and depression?\"\ngenerate_answer(query)\n     \n","metadata":{"execution":{"iopub.status.busy":"2023-11-03T10:25:57.224420Z","iopub.execute_input":"2023-11-03T10:25:57.225347Z","iopub.status.idle":"2023-11-03T10:32:06.940431Z","shell.execute_reply.started":"2023-11-03T10:25:57.225311Z","shell.execute_reply":"2023-11-03T10:32:06.938605Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:381: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.4` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:386: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:381: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.4` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:386: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n  warnings.warn(\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n","output_type":"stream"},{"name":"stdout","text":"-------------------------------------------------\nORIGINAL MODEL RESPONSE:\nAnswer the following question truthfully.\n  If you don't know the answer, respond 'Sorry, I don't know the answer to this question.'.\n  If the question is too complex, respond 'Kindly, consult a psychiatrist for further queries.'.\n<HUMAN>: How can I prevent anxiety and depression?\n  <ASSISTANT>: 1. Keep your life simple. Don't worry about things that haven't happened yet. Worrying doesn't change the outcome of an event. It just makes you anxious and depressed.\n2. Continue with your treatment even if you feel better. Many people stop taking their medication when they feel better, which often leads to another bout of anxiety or depression. This happens because it takes your brain longer to get used to these medications. The best way to deal with anxiety and depression is to continue taking your medication as prescribed by your doctor.\n3. Exercise regularly. Physical exercise helps relieve stress and improves your mood.\n4. Talk to someone you trust. Talking to someone could help reduce your feelings of nervousness and distress. You may also benefit from joining a support group where you can share experiences and learn coping strategies.\n5. Get enough sleep. Lack of sleep worsens symptoms of anxiety and depression.\n6. Avoid alcohol and illicit drugs. Alcohol and illegal drugs affect your thinking and behaviour but do not have any calming effect on most people. They make you more likely to become agitated and less likely to fall asleep.\n7. Follow all medical decisions related to your illness. Some patients try stopping or starting their medicines without consulting their doctors first.\n-------------------------------------------------\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[28], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHow can I prevent anxiety and depression?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mgenerate_answer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[24], line 24\u001b[0m, in \u001b[0;36mgenerate_answer\u001b[0;34m(query)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mORIGINAL MODEL RESPONSE:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mtext_output\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(dashline)\n\u001b[0;32m---> 24\u001b[0m peft_encoding \u001b[38;5;241m=\u001b[39m \u001b[43mpeft_tokenizer\u001b[49m(final_prompt, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     25\u001b[0m peft_outputs \u001b[38;5;241m=\u001b[39m peft_model\u001b[38;5;241m.\u001b[39mgenerate(input_ids\u001b[38;5;241m=\u001b[39mpeft_encoding\u001b[38;5;241m.\u001b[39minput_ids, generation_config\u001b[38;5;241m=\u001b[39mGenerationConfig(max_new_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m, pad_token_id \u001b[38;5;241m=\u001b[39m peft_tokenizer\u001b[38;5;241m.\u001b[39meos_token_id, \\\n\u001b[1;32m     26\u001b[0m                                                                                                                    eos_token_id \u001b[38;5;241m=\u001b[39m peft_tokenizer\u001b[38;5;241m.\u001b[39meos_token_id, attention_mask \u001b[38;5;241m=\u001b[39m peft_encoding\u001b[38;5;241m.\u001b[39mattention_mask, \\\n\u001b[1;32m     27\u001b[0m                                                                                                                    temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.4\u001b[39m, top_p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.6\u001b[39m, repetition_penalty\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.3\u001b[39m, num_return_sequences\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,))\n\u001b[1;32m     28\u001b[0m peft_text_output \u001b[38;5;241m=\u001b[39m peft_tokenizer\u001b[38;5;241m.\u001b[39mdecode(peft_outputs[\u001b[38;5;241m0\u001b[39m], skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n","\u001b[0;31mNameError\u001b[0m: name 'peft_tokenizer' is not defined"],"ename":"NameError","evalue":"name 'peft_tokenizer' is not defined","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}